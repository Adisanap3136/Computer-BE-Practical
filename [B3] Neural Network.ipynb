{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585dbfd6-db68-40fa-b10e-729d44ca7bca",
   "metadata": {},
   "source": [
    "[B3] Given a bank customer, build a neural network-based classifier that can determine whether they will leave or not in the next 6 months. Perform following tasks:\n",
    "\n",
    "1. Read the dataset.\n",
    "\n",
    "2. Distinguish the feature and target set and divide the data set into training and test sets.\n",
    "\n",
    "3. Normalize the train and test data.\n",
    "\n",
    "4. Initialize and build the model. Identify the points of improvement and implement the same.\n",
    "\n",
    "5. Print the accuracy score and confusion matrix (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7eae62-74f3-4e51-a2f8-de7626404420",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2312a715-53c5-497c-8436-98623b6494e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                             # For handling and manipulating data\n",
    "from sklearn.model_selection import train_test_split  # To split data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler       # To normalize features to a standard scale\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # To evaluate model accuracy and generate a confusion matrix\n",
    "from tensorflow.keras.models import Sequential         # To define a neural network model\n",
    "from tensorflow.keras.layers import Dense              # To add fully connected (dense) layers to the model\n",
    "from sklearn.preprocessing import LabelEncoder # For  Conversion of categorical variable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aacb3d-e006-4f19-a478-122cb4112c04",
   "metadata": {},
   "source": [
    "Step 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94601e06-cc76-40a6-896a-84ae0cead112",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')                 # Load dataset and store it in a variable'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b16bc62-c0a6-4ba9-a3f2-89d3794b0f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a54c569-def8-4d41-a366-296e7b466a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359f9c8-5ef0-4eff-8305-8f90465fe3f3",
   "metadata": {},
   "source": [
    "Step 3: Define Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67aeb9ab-cb82-4266-ad1f-16049bfc8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Churn' with the actual column name representing churn in your dataset\n",
    "X = data.drop('Exited', axis=1)   # Drop the column representing churn from features\n",
    "y = data['Exited']                # Define 'y' as the column representing churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad92a2f-b15d-45be-9027-26c5553ce022",
   "metadata": {},
   "source": [
    "Step 4: Split Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c5541a-f67e-4175-8a6d-39369c94c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)      # Split data; 'random_state' ensures reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0d96d-6952-41c7-a3e3-78992252744e",
   "metadata": {},
   "source": [
    "Step 5: Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04e5519-abd6-479a-bafb-bed8b5fa4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert categorical columns to numeric\n",
    "X = pd.get_dummies(X, drop_first=True)  # Encode categorical columns into numeric format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6d68d0-6a32-449b-8ffc-69745696b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and normalizing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5b7bb-eca0-4ecf-a26c-2cbb0dc9a492",
   "metadata": {},
   "source": [
    "Step 6: Build and Initialize the Model\n",
    "\n",
    "We create a simple neural network model with three layers:\n",
    "\n",
    "Input layer: defined by the number of features.\n",
    "\n",
    "Hidden layer: with 16 nodes.\n",
    "\n",
    "Output layer: with one node, since we are predicting a binary outcome (whether they leave or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb23bef-3e84-45e9-8c87-4a4824a80d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4dc16-f5ad-4824-b326-66e3f7900533",
   "metadata": {},
   "source": [
    "Step 7: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a6a76f-c74b-4071-8304-7ee24b0dafd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6056 - loss: 0.6634 - val_accuracy: 0.7994 - val_loss: 0.5239\n",
      "Epoch 2/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.4646 - val_accuracy: 0.8000 - val_loss: 0.5125\n",
      "Epoch 3/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.3998 - val_accuracy: 0.7975 - val_loss: 0.5257\n",
      "Epoch 4/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.3513 - val_accuracy: 0.7850 - val_loss: 0.5450\n",
      "Epoch 5/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.3206 - val_accuracy: 0.7644 - val_loss: 0.5767\n",
      "Epoch 6/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 0.2934 - val_accuracy: 0.7381 - val_loss: 0.6035\n",
      "Epoch 7/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2772 - val_accuracy: 0.7369 - val_loss: 0.6311\n",
      "Epoch 8/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.2578 - val_accuracy: 0.7312 - val_loss: 0.6539\n",
      "Epoch 9/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.2412 - val_accuracy: 0.7225 - val_loss: 0.6898\n",
      "Epoch 10/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.2328 - val_accuracy: 0.7188 - val_loss: 0.7418\n",
      "Epoch 11/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.2202 - val_accuracy: 0.7100 - val_loss: 0.7776\n",
      "Epoch 12/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.2073 - val_accuracy: 0.7212 - val_loss: 0.8274\n",
      "Epoch 13/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9134 - loss: 0.2005 - val_accuracy: 0.7100 - val_loss: 0.8740\n",
      "Epoch 14/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.1890 - val_accuracy: 0.7188 - val_loss: 0.9246\n",
      "Epoch 15/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.1763 - val_accuracy: 0.7100 - val_loss: 0.9631\n",
      "Epoch 16/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.1630 - val_accuracy: 0.7119 - val_loss: 1.0385\n",
      "Epoch 17/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.1518 - val_accuracy: 0.7144 - val_loss: 1.0966\n",
      "Epoch 18/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1396 - val_accuracy: 0.7175 - val_loss: 1.1380\n",
      "Epoch 19/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.1327 - val_accuracy: 0.7163 - val_loss: 1.2463\n",
      "Epoch 20/20\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9505 - loss: 0.1241 - val_accuracy: 0.7219 - val_loss: 1.2426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bbd3657f80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb443f-bc02-46c0-ad28-c8692ba88abe",
   "metadata": {},
   "source": [
    "Step 8: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676879b0-d9bb-4bb8-bd3d-766b071fa2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3f57e5-7a28-4de3-b4c4-f34a1d63573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8168d14c-a62b-4ad6-8422-8cf45e473f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.755\n",
      "Confusion Matrix:\n",
      " [[1387  220]\n",
      " [ 270  123]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
